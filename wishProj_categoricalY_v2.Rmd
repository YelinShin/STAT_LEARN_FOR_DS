---
title: "954:534 Wish Project"
author: "Kanya Kreprasertkul, Yelin Shin and Zhe Ren"
output:
  word_document: default
  html_document:
    df_print: paged
---

```{r, message = FALSE}
options(warn = -1)
library(dplyr)
library(tidyr)
#library(tidyverse)
library(GGally)
library(plotly)
library(cowplot)
library(ggcorrplot)
library(stringr)
```

## Data pre-processing
```{r, results='hide', echo=TRUE}
wish <- read.csv('summer-products-with-rating-and-performance_2020-08.csv')

#dropping unnecessary columns 
drops <- c('title', 'tags', 'crawl_month', 'theme', 'product_id', 'product_picture', 'product_url', 'merchant_id', 'merchant_profile_picture', 'merchant_info_subtitle', 'merchant_name', 'merchant_title', 'urgency_text', 'title_orig', 'shipping_option_name', 'currency_buyer')
wish <- wish[, !(names(wish) %in% drops)]

#convert NA to 0
wish$has_urgency_banner <- as.integer(wish$has_urgency_banner)
wish$has_urgency_banner[which(is.na(wish$has_urgency_banner))] <- 0
wish$rating_five_count[which(is.na(wish$rating_five_count))] <- 0
wish$rating_four_count[which(is.na(wish$rating_four_count))] <- 0
wish$rating_three_count[which(is.na(wish$rating_three_count))] <- 0
wish$rating_two_count[which(is.na(wish$rating_two_count))] <- 0
wish$rating_one_count[which(is.na(wish$rating_one_count))] <- 0
wish$rating[which(wish$rating_count == 0)] <- 0

# cleaning size and color option
wish <- wish %>%
  mutate(product_variation_size_id = tolower(product_variation_size_id)) %>%
  mutate(product_variation_size_id = gsub(pattern = '.', replacement = '',
                                          x = product_variation_size_id, fixed = TRUE)) %>%
  mutate(product_variation_size_id = gsub(pattern = '(size-*)|(size)', replacement = '',
                                          x = product_variation_size_id)) %>%
  mutate(product_variation_size_id = gsub(pattern = '.+[-]', replacement = '',
                                          x = product_variation_size_id)) %>%
  mutate(product_variation_size_id = ifelse(grepl(pattern = 'xl',product_variation_size_id),
                                            'xl', product_variation_size_id)) %>%
  mutate(product_variation_size_id = ifelse(grepl(pattern = 'xs', product_variation_size_id),
                                            'xs', product_variation_size_id)) %>%
  mutate(product_variation_size_id = str_replace(product_variation_size_id, ' ', '')) %>%
  mutate(product_variation_size_id = ifelse(product_variation_size_id %in% c('s', 'xs', 'm', 'l', 'xl'),product_variation_size_id, 'One-sized'))
wish <- wish %>% 
    mutate(product_color = tolower(product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'red|burgundy|claret|wine|jasper', product_color),
                                  'red', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'blue|navy', product_color),
                                  'blue', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'white', product_color),
                                  'white', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'green|army', product_color),
                                  'green', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'black', product_color),
                                  'black', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'yellow|leopard|gold', product_color),
                                  'yellow', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'pink|rose', product_color),
                                  'pink', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'grey|gray|silver', product_color),
                                  'gray', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'purple|violet', product_color),
                                  'purple', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'orange|apricot', product_color),
                                  'orange', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'beige|nude|ivory|coffee|brown|khaki|camel',
                                        product_color), 'khaki', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'floral|multicolor|camouflage|rainbow|star',
                                        product_color), 'multicolor', product_color))

#name blank category 
wish['product_color'][wish['product_color'] == ''] <- 'Not defined'
wish['origin_country'][wish['origin_country'] == ''] <- 'Not defined'

#shipping_is_express has too many zero, so we decided to exclude this column
wish <- select(wish, -c(shipping_is_express))

#Only 7 colors have more than 100 records so We decided to keep only 8 factors of color, i.e. black, white, blue, red, green, yellow, pink and others.
color_list <- c('black', 'white', 'blue', 'red', 'green', 'yellow', 'pink')
wish$product_color[!(wish$product_color %in% color_list)] <- 'others'

wish %>% 
  group_by(product_color) %>%
  summarise(no_rows = length(product_color)) %>%
  arrange(desc(no_rows)) %>%
  filter(no_rows > 100)

#We decided to change origin to CN and others.
wish$origin_country <- as.character(wish$origin_country)
wish$origin_country[which(wish$origin_country != 'CN')] <- 'others'
wish$origin_country[is.na(wish$origin_country)] <- 'others'

wish %>% 
  group_by(origin_country) %>%
  summarise(no_rows = length(origin_country)) %>%
  arrange(desc(no_rows)) 

#convert column name to short version
origin_colname <- colnames(wish)
colnames(wish) <- c('price', 'retail', 'sold_ct', 'ad_boost', 'rate', 'rate_ct', 'rate5', 'rate4', 'rate3', 'rate2', 'rate1', 'badge_ct', 'bg_local', 'bg_quality', 'bg_fastship', 'color', 'size', 'inventory', 'ship_price', 'able_country', 'total_invent', 'has_bg_urgency', 'origin', 'seller_rate_ct', 'seller_rate', 'has_seller_propic')

```

```{r}
library(corrplot)
# finding correlation between numeric columns and charges

numeric.column <- sapply(wish, is.numeric)
corr <- cor(wish[, numeric.column]) #, use = 'pairwise.complete.obs'
corrplot(corr, method = 'color')

```

```{r}
#convert the y (sold_ct) to categorical. Also since it is unbalanced we group some category together.
table(wish['sold_ct']) # very unbalaned
wish_cate <- wish
wish_cate$sold_ct_cate <- wish_cate$sold_ct
wish_cate$sold_ct_cate[which(wish_cate$sold_ct <= 100)] <- 'below 100'
wish_cate$sold_ct_cate[which(wish_cate$sold_ct >= 5000)] <- 'above 5K'
wish_cate$sold_ct_cate[which(wish_cate$sold_ct > 100 & wish_cate$sold_ct < 5000)] <- 'between 100 and 5k'
wish_cate <- select(wish_cate, -sold_ct)
wish_cate$sold_ct_cate <- as.factor(wish_cate$sold_ct_cate)
wish_cate$color <- as.factor(wish_cate$color)
wish_cate$size <- as.factor(wish_cate$size)
wish_cate$origin <- as.factor(wish_cate$origin)
table(wish_cate$sold_ct_cate) # much better

x1 <- factor(wish_cate$sold_ct_cate)
tb <- table(x1)
barplot(tb, names.arg = row.names(tb), cex.names = 0.8, main = "sold_ct as categorical", las = 2)

#percentage of each rate count 
wish_cate$rate5_pct <- wish_cate$rate5/wish_cate$rate_ct
wish_cate$rate4_pct <- wish_cate$rate4/wish_cate$rate_ct
wish_cate$rate3_pct <- wish_cate$rate3/wish_cate$rate_ct
wish_cate$rate2_pct <- wish_cate$rate2/wish_cate$rate_ct
wish_cate$rate1_pct <- wish_cate$rate1/wish_cate$rate_ct

drops <- c('rate_ct', 'rate5', 'rate4', 'rate3', 'rate2', 'rate1')
wish_cate <- wish_cate[, !(names(wish_cate) %in% drops)]

wish_cate <- wish_cate %>% drop_na(rate5_pct) 
wish_cate <- wish_cate %>% drop_na(price) 

summary(wish_cate)

str(wish_cate)

```

## Methodology

#### 80:20 split for train and test set
```{r}

set.seed(123)

train_rows <- sample(1:nrow(wish), 0.8 * nrow(wish))
wish.train <- wish_cate[train_rows, ] # wish training set
wish.test <- wish_cate[-train_rows, ]

wish.train <- wish.train %>% drop_na(price)

```

### Multinomial Regression

```{r}
set.seed(123)
library(nnet)
multinomial.mod <- multinom(sold_ct_cate ~ ., data = wish.train) #, na.action = na.roughfix
summary(multinomial.mod)
multinomial.pred_train <- predict(multinomial.mod, wish.train) 
multinomial.pred_test <- predict(multinomial.mod, wish.test)
# training error
print("Misclassification rate on the training set:")
mean(as.character(multinomial.pred_train) != as.character(wish.train$sold_ct_cate))
# test error
print("Misclassification rate on the test set:")
mean(as.character(multinomial.pred_test) != as.character(wish.test$sold_ct_cate))

confusion.matrix <- table(wish.test$sold_ct_cate, multinomial.pred_test)
print(confusion.matrix)

accuracy.percent <- 100*sum(diag(confusion.matrix))/sum(confusion.matrix)
above5k.precent <- 100*confusion.matrix[1,1]/sum(confusion.matrix[1,])
print(paste("Test accuracy:",accuracy.percent,"%"))
print(paste("Above 5k accuracy:",above5k.precent,"%"))
```

### Dicision Tree Models

```{r}
library(tree)

set.seed(123)

tree.wish <- tree(sold_ct_cate ~ ., data = wish.train) 
summary(tree.wish)
tree.pred <- predict(tree.wish, wish.test, type = "class")

# table(tree.pred, wish.test$sold_ct_cate)

# print("Misclassification error rate on test set: ")

confusion.matrix <- table(wish.test$sold_ct_cate, tree.pred)
print(confusion.matrix)

accuracy.percent <- 100*sum(diag(confusion.matrix))/sum(confusion.matrix)
above5k.precent <- 100*confusion.matrix[1,1]/sum(confusion.matrix[1,])
print(paste("Test accuracy:",accuracy.percent,"%"))
print(paste("Above 5k accuracy:",above5k.precent,"%"))
```

### Bagging

```{r}
library(randomForest)
set.seed(123)

bag.wish <- randomForest(sold_ct_cate ~ ., data = wish.train, mtry = length(wish.train) - 1, importance = TRUE, na.action = na.roughfix)
bag.wish

bag.pred <- predict(bag.wish, wish.test)

confusion.matrix <- table(wish.test$sold_ct_cate, bag.pred)
print(confusion.matrix)

accuracy.percent <- 100*sum(diag(confusion.matrix))/sum(confusion.matrix)
above5k.precent <- 100*confusion.matrix[1,1]/sum(confusion.matrix[1,])
print(paste("Test accuracy:",accuracy.percent,"%"))
print(paste("Above 5k accuracy:",above5k.precent,"%"))

```

### Random forest

```{r}
set.seed(123)

rf.wish <- randomForest(sold_ct_cate ~ ., data = wish.train, mtry = (length(wish.train) - 1) / 3, importance = TRUE, na.action = na.roughfix)
rf.wish

rf.pred <- predict(rf.wish, wish.test)


confusion.matrix <- table(wish.test$sold_ct_cate, rf.pred)
print(confusion.matrix)

accuracy.percent <- 100*sum(diag(confusion.matrix))/sum(confusion.matrix)
above5k.precent <- 100*confusion.matrix[1,1]/sum(confusion.matrix[1,])
print(paste("Test accuracy:",accuracy.percent,"%"))
print(paste("Above 5k accuracy:",above5k.precent,"%"))

```

### SVM

#### Linear

```{r}
library(e1071)
# summary(wish.train)
# summary(wish.test)

set.seed(123)

tuned <- tune(svm, sold_ct_cate ~ ., data = wish.train, kernel = "linear", ranges = list(cost = append(seq(0.01, 10, by = 0.5), 10)))
summary(tuned) 

print("The best cost:")
tuned$best.parameter$cost

lin.svm <- svm(sold_ct_cate ~ ., kernel = "linear", type = "C-class", data = wish.train, cost = tuned$best.parameter$cost)

train_pred <- predict(lin.svm, wish.train, na.action = na.exclude)
table <- table(wish.train$sold_ct_cate, train_pred)

print(paste("accuracy with cost =", tuned$best.parameter$cost, "for train: "))
1-(sum(table)-sum(diag(table))) / (sum(table))

test_pred <- predict(lin.svm, wish.test)
table <- table(wish.test$sold_ct_cate, test_pred)

print(paste("accuracy with cost =", tuned$best.parameter$cost, "for test: "))
1-(sum(table)-sum(diag(table))) / (sum(table))
print(paste("above 5k group - accuracy with cost =", tuned$best.parameter$cost, ": "))
sum(table[1,1]) /sum(table[1,])

# we cannot plot SVM classification plot since we have more than 2 columns
table(wish.test$sold_ct_cate, test_pred)
```

#### Radial

```{r}
# names(wish.train)
set.seed(123)

tuned <- tune(svm, sold_ct_cate ~ ., data = wish.train, kernel = "radial", ranges = list(cost = append(seq(0.01, 15, by = 0.5), 10)))
summary(tuned) 

print("The best cost:")
tuned$best.parameter$cost

rad.svm <- svm(sold_ct_cate ~ ., kernel = "radial", data = wish.train, cost = tuned$best.parameter$cost)

train_pred <- predict(rad.svm, wish.train, na.action = na.exclude)
table <- table(wish.train$sold_ct_cate, train_pred)

print(paste("accuracy with cost =", tuned$best.parameter$cost, "for train: "))
1-(sum(table)-sum(diag(table))) / (sum(table))

test_pred <- predict(rad.svm, wish.test)
table <- table(wish.test$sold_ct_cate, test_pred)

print(paste("accuracy with cost =", tuned$best.parameter$cost, "for test: "))
1-(sum(table)-sum(diag(table))) / (sum(table))
print(paste("above 5k group - accuracy with cost =", tuned$best.parameter$cost, ": "))
sum(table[1,1]) /sum(table[1,])

table(wish.test$sold_ct_cate, test_pred)

```

The result shows that there is overfitting issue. (traing error is getting low, but test error is getting higher)

#### Polynomial

```{r}
set.seed(123)
tune.poly <- tune(svm, sold_ct_cate ~ ., data = wish.train, kernel = "poly", degree = 3, ranges = list(cost = append(seq(0.01, 15, by = 0.5), 10)))
summary(tuned) 

print("The best cost:")
tuned$best.parameter$cost

poly.svm <- svm(sold_ct_cate ~ ., kernel = "poly", data = wish.train, degree = 3, cost = tuned$best.parameter$cost)

train_pred <- predict(poly.svm, wish.train, na.action = na.exclude)
table <- table(wish.train$sold_ct_cate, train_pred)

print(paste("accuracy with cost =", tuned$best.parameter$cost, "for train: "))
1-(sum(table)-sum(diag(table))) / (sum(table))

test_pred <- predict(poly.svm, wish.test)
table <- table(wish.test$sold_ct_cate, test_pred)

print(paste("accuracy with cost =", tuned$best.parameter$cost, "for test: "))
1-(sum(table)-sum(diag(table))) / (sum(table))
print(paste("above 5k group - accuracy with cost =", tuned$best.parameter$cost, ": "))
sum(table[1,1]) /sum(table[1,])

table(wish.test$sold_ct_cate, test_pred)
```

### GBM

```{r}
library(gbm)
boost.wish = gbm(sold_ct_cate ~ ., data = wish.train, distribution = "multinomial", n.trees = 10000, shrinkage = 0.01, interaction.depth = 4)
summary(boost.wish)

boost.predP <- predict(boost.wish, wish.test, n.trees = 10000, type = 'response')

classification <- c("above 5K", "below 100", "between 100 and 5k")
boost.pred <- apply(boost.predP, 1, which.max)
boost.pred <- classification[boost.pred]
confusion.matrix <- table(wish.test$sold_ct_cate, boost.pred)
print(confusion.matrix)

accuracy.percent <- 100*sum(diag(confusion.matrix))/sum(confusion.matrix)
above5k.precent <- 100*confusion.matrix[1,1]/sum(confusion.matrix[1,])
print(paste("Test accuracy:",accuracy.percent,"%"))
print(paste("Above 5k accuracy:",above5k.precent,"%"))

```

### XGBoost

```{r, message = FALSE}
library(xgboost)
# Create numeric labels with one-hot encoding
set.seed(123)
train_labs <- as.numeric(wish.train$sold_ct_cate) - 1 
val_labs <- as.numeric(wish.test$sold_ct_cate) - 1 

# options(na.action='na.pass')
new_train <- model.matrix(~ . + 0, data = subset(wish.train, select = -sold_ct_cate))
new_val <- model.matrix(~ . + 0, data = subset(wish.test, select = -sold_ct_cate))

# Prepare matrices
xgb_train <- xgb.DMatrix(data = new_train, label = train_labs)
xgb_val <- xgb.DMatrix(data = new_val, label = val_labs)

params <- list(booster = "gbtree", objective = "multi:softprob", num_class = 4, eval_metric = "mlogloss")

# Calculate # of folds for cross-validation
xgbcv <- xgb.cv(params = params, data = xgb_train, nrounds = 100, nfold = 5, showsd = TRUE, stratified = TRUE, print_every_n = 10, early_stop_round = 20, maximize = FALSE, prediction = TRUE) 

```

```{r}
# Function to compute classification error
classification_error <- function(conf_mat) {
  conf_mat = as.matrix(conf_mat)
  
  error = 1 - sum(diag(conf_mat)) / sum(conf_mat)
  
  return (error)
}

# Mutate xgb output to deliver hard predictions
xgb_train_preds <- data.frame(xgbcv$pred) %>% mutate(max = max.col(., ties.method = "last"), label = train_labs + 1)

# Examine output
head(xgb_train_preds)

xgb_conf_mat <- table(true = train_labs + 1, pred = xgb_train_preds$max)

# Error 
cat("XGB Training Classification Error Rate:", classification_error(xgb_conf_mat), "\n")

# predicting / testing on test dataset
xgb_model <- xgb.train(params = params, data = xgb_train, nrounds = 100)

# Predict for validation set
xgb_val_preds <- predict(xgb_model, newdata = xgb_val)

xgb_val_out <- matrix(xgb_val_preds, nrow = 4, ncol = length(xgb_val_preds) / 4) %>% 
               t() %>%
               data.frame() %>%
               mutate(max = max.col(., ties.method = "last"), label = val_labs + 1) 

# Confustion Matrix
xgb_val_conf <- table(true = val_labs + 1, pred = xgb_val_out$max)

cat("XGB Validation Classification Error Rate:", 1-classification_error(xgb_val_conf), "\n")
cat("XGB Validation Classification Error Rate - above 5k:", xgb_val_conf[1,1]/sum(xgb_val_conf[1,]), "\n")

```

### Stacked Ensembles 

```{r}
# we already have gbm.wish for GBM, now build RF model
# https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/stacked-ensembles.html
# Stacked Ensemble model's performance is not so different from those of base learners' 
library(h2o)
h2o.init()

wish.train.h2o <- as.h2o(wish.train)
wish.test.h2o <- as.h2o(wish.test)
predictors <- c(colnames(wish.train)[1:length(wish.train) - 1])
response <- "sold_ct_cate"

set.seed(123)

gbm.wish <- h2o.gbm(x = predictors,
                    y = response,
                    nfolds = 5,
                    distribution = "multinomial",
                    keep_cross_validation_predictions = TRUE,
                    training_frame = wish.train.h2o, seed=1)

rf.wish <- h2o.randomForest(x = predictors,
                          y = response,
                          training_frame = wish.train.h2o,
                          ntrees = 50,
                          nfolds = 5,
                          keep_cross_validation_predictions = TRUE,
                          seed = 1)

ensemble <- h2o.stackedEnsemble(x = predictors,
                                y = response,
                                training_frame = wish.train.h2o,
                                base_models = list(gbm.wish, rf.wish))

perf <- h2o.performance(ensemble, newdata = wish.test.h2o)

# Compare to base learner performance on the test set
perf_gbm_test <- h2o.performance(gbm.wish, newdata = wish.test.h2o)
perf_rf_test <- h2o.performance(rf.wish, newdata = wish.test.h2o)
baselearner_best_auc_test <- max(h2o.auc(perf_gbm_test), h2o.auc(perf_rf_test))
ensemble_auc_test <- h2o.auc(perf)
print(sprintf("Best Base-learner Test AUC:  %s", baselearner_best_auc_test))
print(sprintf("Ensemble Test AUC:  %s", ensemble_auc_test))

perf
perf_gbm_test
perf_rf_test

# Generate predictions on a test set 
pred <- h2o.predict(ensemble, newdata = wish.test.h2o)
```

### Neural network

```{r}
library(neuralnet)
library(nnet)
y_index = grep("sold_ct_cate", names(wish.train))
nn.train = cbind(wish.train[, -y_index], wish.train[, y_index])
names(nn.train)[names(nn.train) == 'wish.train[, y_index]'] <- 'sold_ct_cate'


nn.train = cbind(nn.train[, 1:8],class.ind(as.factor(nn.train$color)),nn.train[, 11:15],nn.train[17:24],class.ind(as.factor(nn.train$size)),class.ind(as.factor(nn.train$origin)), class.ind(as.factor(nn.train$sold_ct_cate)))
#normalized by scaling data
scl <- function(x){ (x - min(x))/(max(x) - min(x)) }
nn.train[, 1:29] <- data.frame(lapply(nn.train[, 1:29], scl))

names(nn.train)[names(nn.train) == 'One-sized'] <- 'one_sized'
names(nn.train)[names(nn.train) == 'above 5K'] <- 'above_5k'
names(nn.train)[names(nn.train) == 'below 100'] <- 'below_100'
names(nn.train)[names(nn.train) == 'between 100 and 5k'] <- 'btw_100_5k'

name <- names(nn.train)
f <- as.formula(paste("above_5k + below_100 + btw_100_5k ~", paste(name[!name %in% c("above_5k","below_100","btw_100_5k")], collapse = " + ")))
f
```

```{r}
set.seed(123)
nn <- neuralnet(f,
                data = nn.train,
                hidden = c(37, 15,3),
                act.fct = "logistic",
                linear.output = FALSE,stepmax = 3000)
```

```{r}
plot(nn)
```

```{r}
nn.test = cbind(wish.test[, -y_index], wish.test[, y_index])
names(nn.test)[names(nn.test) == 'wish.test[, y_index]'] <- 'sold_ct_cate'

nn.test = cbind(nn.test[, 1:8], class.ind(as.factor(nn.test$color)), nn.test[, 11:15], nn.test[17:24], class.ind(as.factor(nn.test$size)), class.ind(as.factor(nn.test$origin)), class.ind(as.factor(nn.test$sold_ct_cate)))
#normalized by scaling data
scl <- function(x){ (x - min(x))/(max(x) - min(x)) }
nn.test[, 1:29] <- data.frame(lapply(nn.test[, 1:29], scl))

names(nn.test)[names(nn.test) == 'One-sized'] <- 'one_sized'
names(nn.test)[names(nn.test) == 'above 5K'] <- 'above_5k'
names(nn.test)[names(nn.test) == 'below 100'] <- 'below_100'
names(nn.test)[names(nn.test) == 'between 100 and 5k'] <- 'btw_100_5k'

#train accuracy
nn.train_pred <- compute(nn, nn.train[, 1:37])
nn.train_pred <- nn.train_pred$net.result
true_y.train <- max.col(nn.train[, 38:40])
predicted_y.train <- max.col(nn.train_pred)

#test accuracy
nn.test_pred <- compute(nn, nn.test[, 1:37])
nn.test_pred <- nn.test_pred$net.result
true_y.test <- max.col(nn.test[, 38:40])
predicted_y.test <- max.col(nn.test_pred)

table.train <- table(true_y.train, predicted_y.train)
table.test <- table(true_y.test, predicted_y.test)


print("accuracy for train: ")
print(1-(sum(table.train)-sum(diag(table.train))) / (sum(table.train)))
print("accuracy for test: ")
print(1-(sum(table.test)-sum(diag(table.test))) / (sum(table.test)))

print("above 5k group accuracy:")
sum(table.test[1,1]) /sum(table.test[1,])

```
