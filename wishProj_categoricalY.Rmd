---
title: "954:534 Wish Project"
author: "Kanya Kreprasertkul, Yelin Shin and Zhe Ren"
output:
  html_document:
    df_print: paged
---

```{r, message = FALSE}
options(warn = -1)
library(dplyr)
library(tidyr)
#library(tidyverse)
library(GGally)
library(plotly)
library(cowplot)
library(ggcorrplot)
library(stringr)
```

### Data pre-processing
```{r, results='hide', echo=TRUE}
wish <- read.csv('summer-products-with-rating-and-performance_2020-08.csv')

#dropping unnecessary columns 
drops <- c('title', 'tags', 'crawl_month', 'theme', 'product_id', 'product_picture', 'product_url', 'merchant_id', 'merchant_profile_picture', 'merchant_info_subtitle', 'merchant_name', 'merchant_title', 'urgency_text', 'title_orig', 'shipping_option_name', 'currency_buyer')
wish <- wish[, !(names(wish) %in% drops)]

#convert NA to 0
wish$has_urgency_banner <- as.integer(wish$has_urgency_banner)
wish$has_urgency_banner[which(is.na(wish$has_urgency_banner))] <- 0
wish$rating_five_count[which(is.na(wish$rating_five_count))] <- 0
wish$rating_four_count[which(is.na(wish$rating_four_count))] <- 0
wish$rating_three_count[which(is.na(wish$rating_three_count))] <- 0
wish$rating_two_count[which(is.na(wish$rating_two_count))] <- 0
wish$rating_one_count[which(is.na(wish$rating_one_count))] <- 0
wish$rating[which(wish$rating_count == 0)] <- 0

# cleaning size and color option
wish <- wish %>%
  mutate(product_variation_size_id = tolower(product_variation_size_id)) %>%
  mutate(product_variation_size_id = gsub(pattern = '.', replacement = '',
                                          x = product_variation_size_id, fixed = TRUE)) %>%
  mutate(product_variation_size_id = gsub(pattern = '(size-*)|(size)', replacement = '',
                                          x = product_variation_size_id)) %>%
  mutate(product_variation_size_id = gsub(pattern = '.+[-]', replacement = '',
                                          x = product_variation_size_id)) %>%
  mutate(product_variation_size_id = ifelse(grepl(pattern = 'xl',product_variation_size_id),
                                            'xl', product_variation_size_id)) %>%
  mutate(product_variation_size_id = ifelse(grepl(pattern = 'xs', product_variation_size_id),
                                            'xs', product_variation_size_id)) %>%
  mutate(product_variation_size_id = str_replace(product_variation_size_id, ' ', '')) %>%
  mutate(product_variation_size_id = ifelse(product_variation_size_id %in% c('s', 'xs', 'm', 'l', 'xl'),product_variation_size_id, 'One-sized'))
wish <- wish %>% 
    mutate(product_color = tolower(product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'red|burgundy|claret|wine|jasper', product_color),
                                  'red', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'blue|navy', product_color),
                                  'blue', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'white', product_color),
                                  'white', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'green|army', product_color),
                                  'green', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'black', product_color),
                                  'black', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'yellow|leopard|gold', product_color),
                                  'yellow', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'pink|rose', product_color),
                                  'pink', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'grey|gray|silver', product_color),
                                  'gray', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'purple|violet', product_color),
                                  'purple', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'orange|apricot', product_color),
                                  'orange', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'beige|nude|ivory|coffee|brown|khaki|camel',
                                        product_color), 'khaki', product_color)) %>%
    mutate(product_color = ifelse(grepl(pattern = 'floral|multicolor|camouflage|rainbow|star',
                                        product_color), 'multicolor', product_color))

#name blank category 
wish['product_color'][wish['product_color'] == ''] <- 'Not defined'
wish['origin_country'][wish['origin_country'] == ''] <- 'Not defined'

#shipping_is_express has too many zero, so we decided to exclude this column
wish <- select(wish, -c(shipping_is_express))

#Only 7 colors have more than 100 records so We decided to keep only 8 factors of color, i.e. black, white, blue, red, green, yellow, pink and others.
color_list <- c('black', 'white', 'blue', 'red', 'green', 'yellow', 'pink')
wish$product_color[!(wish$product_color %in% color_list)] <- 'others'

wish %>% 
  group_by(product_color) %>%
  summarise(no_rows = length(product_color)) %>%
  arrange(desc(no_rows)) %>%
  filter(no_rows > 100)

#We decided to change origin to CN and others.
wish$origin_country <- as.character(wish$origin_country)
wish$origin_country[which(wish$origin_country != 'CN')] <- 'others'
wish$origin_country[is.na(wish$origin_country)] <- 'others'

wish %>% 
  group_by(origin_country) %>%
  summarise(no_rows = length(origin_country)) %>%
  arrange(desc(no_rows)) 

#convert column name to short version
origin_colname <- colnames(wish)
colnames(wish) <- c('price', 'retail', 'sold_ct', 'ad_boost', 'rate', 'rate_ct', 'rate5', 'rate4', 'rate3', 'rate2', 'rate1', 'badge_ct', 'bg_local', 'bg_quality', 'bg_fastship', 'color', 'size', 'inventory', 'ship_price', 'able_country', 'total_invent', 'has_bg_urgency', 'origin', 'seller_rate_ct', 'seller_rate', 'has_seller_propic')

```

```{r}
library(corrplot)
# finding correlation between numeric columns and charges

numeric.column <- sapply(wish, is.numeric)
corr <- cor(wish[, numeric.column]) #, use = 'pairwise.complete.obs'
corrplot(corr, method = 'color')

```

```{r}
#convert the y (sold_ct) to categorical. Also since it is unbalanced we group some category together.
table(wish['sold_ct']) # very unbalaned
wish_cate <- wish
wish_cate$sold_ct_cate <- wish_cate$sold_ct
wish_cate$sold_ct_cate[which(wish_cate$sold_ct <= 50)] <- 'below 50'
wish_cate$sold_ct_cate[which(wish_cate$sold_ct >= 20000)] <- 'above 20K'
wish_cate <- select(wish_cate, -sold_ct)
wish_cate$sold_ct_cate <- as.factor(wish_cate$sold_ct_cate)
wish_cate$color <- as.factor(wish_cate$color)
wish_cate$size <- as.factor(wish_cate$size)
wish_cate$origin <- as.factor(wish_cate$origin)
table(wish_cate$sold_ct_cate) # much better

x1 <- factor(wish_cate$sold_ct_cate, levels = c("below 50", "100", "1000", "5000", "10000", "above 20K"))
tb <- table(x1)
barplot(tb, names.arg = row.names(tb), cex.names = 0.8, main = "sold_ct as categorical", las = 2)

str(wish_cate)

```


#### 80:20 split for train and test set
```{r}
set.seed(123)
train_rows <- sample(1:nrow(wish), 0.8 * nrow(wish))
wish.train <- wish_cate[train_rows, ] # wish training set
wish.test <- wish_cate[-train_rows, ]
```

### Multinomial regression

```{r}
set.seed(123)
library(nnet)
multinomial.mod <- multinom(sold_ct_cate ~ ., data = wish.train) 
summary(multinomial.mod)
multinomial.pred_train <- predict(multinomial.mod, wish.train) 
multinomial.pred_test <- predict(multinomial.mod, wish.test)
# training error
print("Misclassification rate on the training set:")
mean(as.character(multinomial.pred_train) != as.character(wish.train$sold_ct_cate))
# test error
print("Misclassification rate on the test set:")
mean(as.character(multinomial.pred_test) != as.character(wish.test$sold_ct_cate))
```

```{r}
library(e1071)

set.seed(120)

tuned <- tune(svm, sold_ct_cate ~ ., data = wish.train, kernel = "linear", ranges = list(cost = append(seq(0.01, 10, by = 0.5), 10)))
summary(tuned) # cost = 3.51 is the best

lin.svm <- svm(sold_ct_cate ~ ., kernel = "linear", type = "C-class", data = wish.train, cost = 3.51)

train_pred <- predict(lin.svm, wish.train)
table <- table(wish.train$sold_ct_cate, train_pred)

print("training error with cost = 3.51: ")
(sum(table)-sum(diag(table))) / (sum(table))

test_pred <- predict(lin.svm, wish.test)
table <- table(wish.test$sold_ct_cate, test_pred)

print("training error with cost = 3.51: ")
(sum(table)-sum(diag(table))) / (sum(table))

# we cannot plot SVM classification plot since we have more than 2 columns
table(wish.test$sold_ct_cate, test_pred)
```

```{r}
set.seed(123)

tuned <- tune(svm, sold_ct_cate ~ ., data = wish.train, kernel = "radial", ranges = list(cost = append(seq(0.01, 10, by = 0.5), 10)))
summary(tuned) # cost = 10 is best

table(wish.test$sold_ct_cate, test_pred)

rad.svm <- svm(sold_ct_cate ~ ., kernel = "radial", data = wish.train, cost = 10)

train_pred <- predict(rad.svm, wish.train)
table <- table(wish.train$sold_ct_cate, train_pred)

print("radical svm - training error with cost = 10: ")
(sum(table)-sum(diag(table))) / (sum(table))

test_pred <- predict(rad.svm, wish.test)
table <- table(wish.test$sold_ct_cate, test_pred)

print("radical svm - training error with cost = 10: ")
(sum(table)-sum(diag(table))) / (sum(table))

table(wish.test$sold_ct_cate, test_pred)

```

The result shows that it result overfitting. (traing error is getting low, but test error is getting higher)

```{r}
tune.poly <- tune(svm, sold_ct_cate ~ ., data = wish.train, kernel = "poly", degree = 3, ranges = list(cost = append(seq(0.01, 10, by = 0.5), 10)))
summary(tuned) # cost = 10 is best

poly.svm <- svm(sold_ct_cate ~ ., kernel = "poly", data = wish.train, degree = 3, cost = 10)

train_pred <- predict(poly.svm, wish.train)
table <- table(wish.train$sold_ct_cate, train_pred)

print("poly svm - training error with cost = 10: ")
(sum(table)-sum(diag(table))) / (sum(table))

test_pred <- predict(poly.svm, wish.test)
table <- table(wish.test$sold_ct_cate, test_pred)

print("poly svm - training error with cost = 10: ")
(sum(table)-sum(diag(table))) / (sum(table))

table(wish.test$sold_ct_cate, test_pred)
```


### XGBoost
```{r, message = FALSE}
library(xgboost)
# Create numeric labels with one-hot encoding
train_labs <- as.numeric(wish.train$sold_ct_cate) - 1
val_labs <- as.numeric(wish.test$sold_ct_cate) - 1

new_train <- model.matrix(~ . + 0, data = subset(wish.train, select = -sold_ct_cate))
new_val <- model.matrix(~ . + 0, data = subset(wish.test, select = -sold_ct_cate))

# Prepare matrices
xgb_train <- xgb.DMatrix(data = new_train, label = train_labs)
xgb_val <- xgb.DMatrix(data = new_val, label = val_labs)

params <- list(booster = "gbtree", objective = "multi:softprob", num_class = 8, eval_metric = "mlogloss")

# Calculate # of folds for cross-validation
xgbcv <- xgb.cv(params = params, data = xgb_train, nrounds = 100, nfold = 5, showsd = TRUE, stratified = TRUE, print_every_n = 10, early_stop_round = 20, maximize = FALSE, prediction = TRUE)

```

```{r}
# Function to compute classification error
classification_error <- function(conf_mat) {
  conf_mat = as.matrix(conf_mat)
  
  error = 1 - sum(diag(conf_mat)) / sum(conf_mat)
  
  return (error)
}

# Mutate xgb output to deliver hard predictions
xgb_train_preds <- data.frame(xgbcv$pred) %>% mutate(max = max.col(., ties.method = "last"), label = train_labs + 1)

# Examine output
head(xgb_train_preds)

xgb_conf_mat <- table(true = train_labs + 1, pred = xgb_train_preds$max)

# Error 
cat("XGB Training Classification Error Rate:", classification_error(xgb_conf_mat), "\n")

# predicting / testing on test dataset
xgb_model <- xgb.train(params = params, data = xgb_train, nrounds = 100)

# Predict for validation set
xgb_val_preds <- predict(xgb_model, newdata = xgb_val)

xgb_val_out <- matrix(xgb_val_preds, nrow = 8, ncol = length(xgb_val_preds) / 8) %>% 
               t() %>%
               data.frame() %>%
               mutate(max = max.col(., ties.method = "last"), label = val_labs + 1) 

# Confustion Matrix
xgb_val_conf <- table(true = val_labs + 1, pred = xgb_val_out$max)

cat("XGB Validation Classification Error Rate:", classification_error(xgb_val_conf), "\n")

```
